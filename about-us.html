<!DOCTYPE html>
<html lang="en">

<head>
    <!-- ========== Meta Tags ========== -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Edukat - Education and LMS Template">

    <!-- ========== Page Title ========== -->
    <title>Bio-asp Lab</title>

    <!-- ========== Favicon Icon title符號 ========== -->
    <link rel="icon" href="assets/img/logo.ico" type="image/x-icon" >
    <link rel="shortcut icon" href="assets/img/logo.ico" type="image/x-icon">

    <!-- ========== Start Stylesheet ========== -->
    <link href="assets/css/bootstrap.min.css" rel="stylesheet" />
    <link href="assets/css/font-awesome.min.css" rel="stylesheet" />
    <link href="assets/css/themify-icons.css" rel="stylesheet" />
    <link href="assets/css/flaticon-set.css" rel="stylesheet" />
    <link href="assets/css/elegant-icons.css" rel="stylesheet" />
    <link href="assets/css/magnific-popup.css" rel="stylesheet" />
    <link href="assets/css/owl.carousel.min.css" rel="stylesheet" />
    <link href="assets/css/owl.theme.default.min.css" rel="stylesheet" />
    <link href="assets/css/animate.css" rel="stylesheet" />
    <link href="assets/css/bootsnav.css" rel="stylesheet" />
    <link href="style.css" rel="stylesheet">
    <link href="assets/css/responsive.css" rel="stylesheet" />
    <!-- ========== End Stylesheet ========== -->

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="assets/js/html5/html5shiv.min.js"></script>
      <script src="assets/js/html5/respond.min.js"></script>
    <![endif]-->

    

</head>

<body>

    <!-- Preloader Start -->
    <div class="se-pre-con"></div>
    <!-- Preloader Ends -->

    <!-- Start Header Top 
    ============================================= -->
    <div class="top-bar-area bg-dark text-light inline inc-border">
        <div class="container">
            <div class="row align-center">
                
                <div class="col-lg-7 col-md-12 left-info">
                    <div class="item-flex">
                        <ul class="list">
                            <li>
                                <i class="far fa-thumbs-up"></i> Welcome to Bio-ASP Lab ~
                            </li>
                        </ul>
                    </div>
                </div>

            </div>
        </div>
    </div>
    <!-- End Header Top -->

    <!-- Header 
    ============================================= -->
    <header id="home">

        <!-- Start Navigation -->
        <nav class="navbar shadow-less navbar-default navbar-sticky bootsnav">

            <div class="container">

                <!-- Start Header Navigation -->
                <div class="navbar-header">
                    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar-menu">
                        <i class="fa fa-bars"></i>
                    </button>
                    <a class="navbar-brand" href="index.html">
                        <img src="assets/img/logo.jpg" class="logo" alt="Logo">
                    </a>
                </div>
                <!-- End Header Navigation -->

                <!-- Collect the nav links, forms, and other content for toggling --><!-- Menu -->
                <div class="collapse navbar-collapse" id="navbar-menu">
                    <ul class="nav navbar-nav navbar-right" data-in="fadeInDown" data-out="fadeOutUp">
                        <li>
                            <a href="index.html"><i class="fas fa-home"></i> Home</a>
                        </li>
                        <li class="dropdown">
                            <a href="about-us.html" class="dropdown-toggle" data-toggle="dropdown" >Lab</a>
                            <ul class="dropdown-menu">
                                <li><a href="about-us.html">About Us</a></li>
                                <li><a href="members.html">Team Members</a></li>
                                <li><a href="honor.html">Honors</a></li>
                                <li><a href="news.html">News Report</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="publication.html" class="dropdown-toggle" data-toggle="dropdown" >Publications</a>
                            <ul class="dropdown-menu">
                                <li><a href="p-book.html">Book</a></li>
                                <li><a href="publication.html">Conference</a></li>
                                <li><a href="p-journal.html">Journal</a></li>
                                <li><a href="p-tutorials.html">Tutorials</a></li>
                                <li><a href="p-presentations.html">Presentations</a></li>
                                <li><a href="p-reports.html">Reports</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="Opensource.html" class="dropdown-toggle" data-toggle="dropdown" >Resources</a>
                            <ul class="dropdown-menu">
                                <li><a href="log-in.html">Internal Source</a></li>
                                <li><a href="Opensource.html#SE">Speech Enhancement Tools</a></li>
                                <li><a href="Opensource.html#BSP">Biomedical Signal Processing</a></li>
                                <li><a href="Opensource.html#ET">Evaluation Tool</a></li>
                                <li><a href="Opensource.html#Dataset">Dataset</a></li>
                            </ul>
                        </li>

                        <li>
                            <a href="album.html">Album</a>
                        </li>

                        <li>
                            <a href="contact.html">Contact</a>
                        </li>
                        <li>
                            <a href="https://youtube.com/channel/UCnFK2taEDuu4FaKbMGWYUNg" target="_blank" >
                                <img src="assets/img/youtube.png" width="30px">
                            </a>
                        </li>
                        <li>
                            <a href="https://www.citi.sinica.edu.tw/pages/yu.tsao/index_en.html" target="_blank">
                                <img src="assets/img/profile.png" width="30px">
                            </a>
                        </li>

                    </ul>
                </div><!-- /.navbar-collapse -->
            </div>

        </nav>
        <!-- End Navigation -->

    </header>
    <!-- End Header -->


    <!-- Start Breadcrumb 
    ============================================= -->
    <div class="breadcrumb-area bg-gray text-center  text-light bg-cover" style="background-image: url(assets/img/25.png);">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 offset-lg-2">
                    <h1 style="color: royalblue;">About Us</h1>
                </div>
            </div>
        </div>
    </div>
    <!-- End Breadcrumb -->

    <!-- Star About Area
    ============================================= -->
    <div class="about-area default-padding-top">
        <!-- Fixed Shape -->
        <div class="fixed-shape-bottom">
            <img src="assets/img/shape/12.png" alt="Shape">
        </div>
        <!-- End Fixed Shape -->
        <div class="container">
            <div class="about-items">
                <div class="row align-center">
                    
                    <div class="col-lg-6 info">
                        <h2>
                            The Bio-ASP Lab
                        </h2>
                        <p style="font-size: 16px; text-align: justify; color: #000;">
                             In CITI, Academia Sinica was founded in November, 2011. We are dedicated to developing novel acoustic signal processing and artificial intelligence algorithms and apply them to biomedical and biology related tasks. <br/>
                            <br/>
                            The main research focuses include five parts:<br/></p>
                            <p style="margin-left: 2em; font-size: 16px; color: #000;"><img src="assets/img/1.png" width="25"><a href="#major-1"> AI for assistive speech communication technologies</a><br/></p> 
                            <p style="margin-left: 2em; font-size: 16px; color: #000;"><img src="assets/img/2.png" width="25"><a href="#major-2"> Deep learning based speech signal processing</a><br/></p> 
                            <p style="margin-left: 2em; font-size: 16px; color: #000;"><img src="assets/img/3.png" width="25"><a href="#major-3"> Multi-modal speech signal processing</a><br/></p> 
                            <p style="margin-left: 2em; font-size: 16px; color: #000;"><img src="assets/img/4.png" width="25"><a href="#major-4"> Voice-based forensics</a><br/></p> 
                            <p style="margin-left: 2em; font-size: 16px; color: #000;"><img src="assets/img/5.png" width="25"><a href="#major-5"> Soundscape information retrieval</a><br/></p> 
                            <p style="font-size: 16px; text-align: justify; color: #000;">
                            So far, the Bio-ASP Lab has published more than 52 journal papers and 120 international conference papers. Among them, the Bio-ASP Lab received Best Poster Presentation Award in IEEE MIT URTC 2017, Poster Presentation Award in APSIPA 2017, Best Paper Award in ROCLING 2017, Excellent Paper Award in TAAI 2012. Meanwhile, an Interspeech 2014 paper received the best paper award nomination, four papers have received the ISCA travel grant awards, and one paper received the ICML travel grant. A co-advised PhD student received the PhD Thesis Award by ACLCLP in 2018. The Bio-ASP Lab also received the Career Development Award, Academia Sinica in 2017, and National Innovation Award in 2018.
                        </p>

                    </div>

                    <div class="col-lg-6 ">
                        <img src="assets/img/lab-img.JPG" alt="Thumb">
                    </div>

                </div>
            </div>
        </div>
    </div>
    <!-- End About Area -->

    <!-- What we do ?
    ============================================= -->
    <div class="blog-area default-padding bottom-less">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 offset-lg-2">
                    <div class="site-heading text-center">
                        <h2>What we do ?</h2>
                    </div>
                </div>
            </div>
        </div>
        <div class="container">
            <div class="blog-items">
                <div class="row">
                    <!-- Single Item -->
                    <div class="col-lg-4 col-md-6 ">
                        <div class="item">
                            <div class="item malachite">
                                <img src="assets/img/learn.png">
                            </div>
                            <div class="content">
                                <h4>Education</h4>
                            </div>
                        </div>
                    </div>
                    <!-- End Single Item -->
                    <!-- Single Item -->
                    <div class="col-lg-4 col-md-6 ">
                        <div class="item">
                            <div class="item malachite">
                                <img src="assets/img/acoustics.png">
                            </div>
                            <div class="content">
                                <h4>Bio-acoustics</h4>
                            </div>
                        </div>
                    </div>
                    <!-- End Single Item -->
                    <!-- Single Item -->
                    <div class="col-lg-4 col-md-6 ">
                        <div class="item">
                            <div class="item malachite">
                                <img src="assets/img/healthcare.png">
                            </div>
                            <div class="content">
                                <h4>Health Care</h4>
                            </div>
                        </div>
                    </div>
                    <!-- End Single Item -->
                    <!-- Single Item -->
                    <div class="col-lg-4 col-md-6 ">
                        <div class="item">
                            <div class="item malachite">
                                <img src="assets/img/arrest.png">
                            </div>
                            <div class="content">
                                <h4>Forensics</h4>
                            </div>
                        </div>
                    </div>
                    <!-- End Single Item -->
                    <!-- Single Item -->
                    <div class="col-lg-4 col-md-6 ">
                        <div class="item">
                            <div class="item malachite">
                                <img src="assets/img/Chat.png">
                            </div>
                            <div class="content">
                                <h4>Chat box</h4>
                            </div>
                        </div>
                    </div>
                    <!-- End Single Item -->
     
                </div>
            </div>
        </div>
    </div>
    <!-- End What we do ? -->
    

        <!-- Start Advisor Details 
    ============================================= -->
    <div class="advisor-details-area default-padding">
        <div class="container">

            <div class="col-lg-8 offset-lg-2">
                <div class="site-heading text-center" >
                    <h2>Main Researchs</h2>
                </div>
            </div>

            <!-- Single Item -->
                <div class="row" style="margin-bottom: 25px;" id="major-1">
                <div class="col-lg-4 basic-info" >
                    <img src="assets/img/research/AI1.png" >
                </div>
                <div class="col-lg-8 info">
                    <h2 style="font-size: 24px; text-decoration:underline;">
                        <img src="assets/img/1.png" width="30">
                        AI for assistive speech communication technologies</h2>
                        <br>
                    <p style="text-align:justify; text-indent: 2em;">
                        The proportional increase in the elderly population and the inappropriate use of portable 
                        audio devices have led to a rapid increase in incidents of hearing loss.<br>
                    </p>
                    <p style="text-align:justify; text-indent: 2em;">
                        Untreated hearing loss can cause feelings of loneliness and isolation in the elderly and may
                         lead to learning difficulties in students. Over the past few years, our group has investigated
                         the application of machine learning and signal processing algorithms in FM assistive hearing systems [1, 2],
                         hearing aids [3, 4], and cochlear implants (CIs) [5-7] to improve speech communication in hearing-impaired
                         patients and the subsequent enhancement in their quality of life. In addition to assistive listening devices,
                         we have also investigated the development of machine learning-based assistive speaking devices to enhance 
                         intelligibility in individuals with speech and language disorders [8].<br>
                    </p>
                    <p style="text-align:justify; text-indent: 2em;">
                        Oral cancer ranks in the top five of all cancers in Taiwan. To treat the oral cancer, surgical processes 
                        are often required to have parts of the patients’ articulators removed. Because of the removal of parts of
                        the articulator, a patient’s speech may be distorted and difficult to understand. To overcome this problem,
                        we propose two voice conversion (VC) approaches: the first one is the joint dictionary training non-negative
                         matrix factorization (JD-NMF), and the second one is the end-to-end generative adversarial network (GAN)-based
                        unsupervised VC model [9]. Experimental results show that both approaches can be applied to convert the
                         distorted speech signals to the ones with improved intelligibility. 
                    </p>
                    <div class="panel-group" id="accordion">
                        <div class="panel panel-default">
                            <div class="panel-heading">
                                <h4 class="panel-title" >
                                    <a data-toggle="collapse" data-parent="#accordion" 
                                    href="#collapseOne" style="color: blue;">
                                    <i class="fas fa-angle-double-right"></i>  Reference
                                    </a>
                                </h4>
                            </div>
                            <div id="collapseOne" class="panel-collapse collapse in">
                                <div class="panel-body">
                                    <p>[1] A. Chern, Y.-H. Lai, Y.-p. Chang, Y. Tsao, R. Y. Chang, and H.-W. Chang, “A Smartphone-Based Multi-Functional Hearing Assistive System to Facilitate Speech Recognition in the Classroom,” IEEE Access, vol. 5, pp. 10339-10351, 2017 (This paper has been selected as a Featured Article in IEEE Access).</p>
                                    <p>[2] Y.-C. Lin, Y.-H. Lai, H.-W. Chang, Y. Tsao, Y.-p. Chang, and R. Y. Chang, “A Smartphone-Based Remote Microphone Hearing Assistive System Using Wireless Technologies,” IEEE Systems Journal, vol. 12(1), pp. 20-29, 2018.</p>
                                    <p>[3] Y.-T. Liu, R. Y. Chang, Y. Tsao, and Y.-p. Chang, “A New Frequency Lowering Technique for Mandarin-speaking Hearing Aid Users,” in Proc. GlobalSIP 2015.</p>
                                    <p>[4] Y.-T. Liu, Y. Tsao, and R. Y. Chang, “Nonnegative Matrix Factorization-based Frequency Lowering Technology for Mandarin-speaking Hearing Aid Users,” in. Proc. ICASSP 2016.</p>
                                    <p>[5] Y.-H. Lai, Y. Tsao, X. Lu, F. Chen, Y.-T. Su, K.-C. Chen, Y.-H. Chen, L.-C. Chen, P.-H. Li, and C.-H. Lee, “Deep Learning based Noise Reduction Approach to Improve Speech Intelligibility for Cochlear Implant Recipients,” Ear and Hearing, vol. 39(4), pp. 795-809, 2018.</p>
                                    <p>[6] Y.-H. Lai, F. Chen, S.-S. Wang, X. Lu, Y. Tsao, and C.-H. Lee, “A Deep Denoising Autoencoder Approach to Improving the Intelligibility of Vocoded Speech in Cochlear Implant Simulation,” IEEE Transactions on Biomedical Engineering, vol. 64(7), pp. 1568-1578, 2017.</p>
                                    <p>[7] Y.-H. Lai, Y. Tsao, and F. Chen, “Effects of Adaptation Rate and Noise Suppression on the Intelligibility of Compressed-Envelope Based Speech,” PLoS ONE, vol. 10.1371, journal.pone.0133519, 2015.</p>
                                    <p>[8] S.-W. Fu, P.-C. Li, Y.-H. Lai, C.-C. Yang, L.-C. Hsieh, and Y. Tsao, “Joint Dictionary Learning-based Non-Negative Matrix Factorization for Voice Conversion to Improve Speech Intelligibility After Oral Surgery,” IEEE Transactions on Biomedical Engineering, vol. 64 (11), pp. 2584-2594, 2016.</p>  
                                    <p>[9] L.-W. Chen, H.-Y. Lee, and Y. Tsao, “Generative Adversarial Networks for Unpaired Voice Transformation on Impaired Speech,” http://arxiv.org/abs/1810.12656</p>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            <!-- End Single Item -->

            <!-- Single Item -->
                <div class="row" style="margin-bottom: 30px;" id="major-2">
                    <div class="col-lg-4 basic-info">
                        <img src="assets/img/research/Deep.png" >
                    </div>
                    <div class="col-lg-8 info">
                        <h2 style="font-size: 24px; text-decoration:underline;">
                            <img src="assets/img/2.png" width="30">
                            Deep learning-based speech signal processing</h2>
                            <br>
                        <p style="text-align:justify; text-indent: 2em;">
                            In this investigation, we focused on deriving novel deep learning-based algorithms for denoising [10],
                            dereverberation [11], and channel compensation [12] on speech signals. The goal is to enhance the
                            speech signals in order to achieving improved human-human and human-machine communication efficacy.<br>
                        </p>
                        <p style="text-align:justify; text-indent: 2em;">
                            We investigated approaches to enhance speech intelligibility [13] and quality [14] to facilitate higher
                            speech recognition rates and improved communication. We also proposed end-to-end waveform enhancement to
                            directly improve the intelligibility and quality of speech. In addition, we have developed a novel 
                            integrated deep and ensemble learning algorithm (IDEA) [15] and an environment-adaptive 
                            algorithm (based on the domain adversarial training criterion) [16] for speech signal processing to 
                            address possible mismatched issues in real-world applications.<br>
                        </p>
                        <div class="panel-group" id="accordion">
                            <div class="panel panel-default">
                                <div class="panel-heading">
                                    <h4 class="panel-title" >
                                        <a data-toggle="collapse" data-parent="#accordion" 
                                        href="#collapseOne" style="color: blue;">
                                        <i class="fas fa-angle-double-right"></i>  Reference
                                        </a>
                                    </h4>
                                </div>
                                <div id="collapseOne" class="panel-collapse collapse in">
                                    <div class="panel-body">
                                        <p>[10] X. Lu, Y. Tsao, S. Matsuda, and C. Hori, C, “Speech Enhancement Based on Deep Denoising Autoencoder,” in Proc. Interspeech 2013.</p>
                                        <p>[11] W.-J. Lee, S.-S. Wang, F. Chen, X. Lu, S.-Y. Chien, and Y. Tsao, “Speech Dereverberation Based on Integrated Deep and Ensemble Learning Algorithm,” in Proc. ICASSP 2018.</p>
                                        <p>[12] H.-P. Liu, Y. Tsao, Y., and C.-S. Fuh, “Bone-Conducted Speech Enhancement Using Deep Denoising Autoencoder,” Speech Communication, vol. 104, pp. 106-112, 2018.</p>
                                        <p>[13] S.-W. Fu, T.-W. Wang, Y. Tsao, X. Lu, and H. Kawai, “End-to-End Waveform Utterance Enhancement for Direct Evaluation Metrics Optimization by Fully Convolutional Neural Networks,” IEEE Transactions on Audio, Speech and Language Processing, vol. 26(9), pp. 1570-1584, 2018.</p>
                                        <p>[14] S.-W. Fu, Y. Tsao, H.-T. Hwang, and H.-M. Wang, “Quality-Net: An End-to-End Non-intrusive Speech Quality Assessment Model based on BLSTM,” in Proc. Interspeech 2018.</p>
                                        <p>[15] X, Lu, Y. Tsao, S, Matsuda and C, Hori, “Ensemble Modeling of Denoising Autoencoder for Speech Spectrum Restoration,” pp. 885-889, in Proc. Interspeech 2014.</p>
                                        <p>[16] C.-F. Liao, Y. Tsao, H.-y. Lee, and H.-M. Wang, “Noise Adaptive Speech Enhancement using Domain Adversarial Training,” Interspeech, 2019.</p>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            <!-- End Single Item -->

            <!-- Single Item -->
                <div class="row" style="margin-bottom: 25px;" id="major-3">
                    <div class="col-lg-4 basic-info">
                        <img src="assets/img/research/M1.JPG" >
                    </div>
                    <div class="col-lg-8 info">
                        <h2 style="font-size: 24px; text-decoration:underline;">
                            <img src="assets/img/3.png" width="30">
                            Multimodal speech signal processing</h2>
                            <br>
                        <p style="text-align:justify; text-indent: 2em;">
                            Communication can be verbal or nonverbal. Verbal communication includes speaking and listening.<br>
                        </p>
                        <p style="text-align:justify; text-indent: 2em;">
                            The speaker relays verbal information while the listener focuses on auditory signals and the visual 
                            cues for speech recognition. The visual signals may include articulatory movements, facial expressions,
                            and co-speech gestures of the speaker, which constitutes the nonverbal part of the communication 
                            process. In various applied speech technologies, it has been shown that audio-visual integration can 
                            assist in human information exchange and the development of human-computer interfaces. We have conducted
                            studies on the incorporation of audio and video information to facilitate improved speech signal
                            processing performance.<br>
                        </p>
                        <p style="text-align:justify; text-indent: 2em;">
                            Currently, we have developed novel algorithms by fusing the audio and visual information for emotion 
                            recognition [17], oral presentation scoring [18], and speech enhancement [19]
                        </p>
                        <div class="panel-group" id="accordion">
                            <div class="panel panel-default">
                                <div class="panel-heading">
                                    <h4 class="panel-title" >
                                        <a data-toggle="collapse" data-parent="#accordion" 
                                        href="#collapseOne" style="color: blue;">
                                        <i class="fas fa-angle-double-right"></i>  Reference
                                        </a>
                                    </h4>
                                </div>
                                <div id="collapseOne" class="panel-collapse collapse in">
                                    <div class="panel-body">
                                        <p>[17] W.-C. Chen, P.-T. Lai, Y. Tsao, and C.-C. Lee, “Multimodal Arousal Rating using Unsupervised Fusion Technique,” in Proc. ICASSP 2015.</p>
                                        <p>[18] S.-W. Hsiao, H.-C. Sun, M.-C. Hsieh, M.-H. Tsai, Y. Tsao, and C.-C. Lee, “Toward Automating Oral Presentation Scoring during Principal Certification Program using Audio-Video Low-level Behavior Profiles,” IEEE Transactions on Affective Computing, in press.</p>
                                        <p>[19] J.-C. Hou, S.-S. Wang, Y.-H. Lai, Y. Tsao, H.-W. Chang, and H.-M. Wang, “Audio-visual Speech Enhancement using Multimodal Deep Convolutional Neural Networks,” IEEE Transactions on Emerging Topics in Computational Intelligence, vol. 2(2), pp. 117-128, 2018.</p>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            <!-- End Single Item -->

            <!-- Single Item -->
                <div class="row" style="margin-bottom: 25px;" id="major-4">
                    <div class="col-lg-4 basic-info">
                        <img src="assets/img/research/I1.png" >
                    </div>
                    <div class="col-lg-8 info">
                        <h2 style="font-size: 24px; text-decoration:underline;">
                            <img src="assets/img/4.png" width="30">
                            Increasing Compactness of Deep Learning based Speech Enhancement Models</h2>
                            <br>
                        <p style="text-align:justify; text-indent: 2em;">
                            Most recent studies on deep learning-based speech enhancement (SE) have focused on improving the 
                            denoising performance. However, successful SE application requires the achievement of a balance between
                            denoising performance and computational cost in real scenarios.We have investigated two approaches to 
                            effectively compress deep learning models so that the SE can be performed at edge sides.<br>
                        </p>
                        <p style="text-align:justify; text-indent: 2em;">
                            These approaches are model pruning and parameter quantization. In model pruning, a computation-performance 
                            optimization (CPO) algorithm was developed [20] for the removal of redundant channels in a neural network,
                            as shown in Fig. 4. For parameter quantization, we proposed an exponent-only floating point quantized 
                            neural network (EOFP-QNN) to compress the model and enhance inference efficiency [21]. Both the model
                            pruning and parameter quantization techniques can significantly reduce model size and increase inference
                            efficiency with an acceptable drop in performance.<br>
                        </p>
                        <div class="panel-group" id="accordion">
                            <div class="panel panel-default">
                                <div class="panel-heading">
                                    <h4 class="panel-title" >
                                        <a data-toggle="collapse" data-parent="#accordion" 
                                        href="#collapseOne" style="color: blue;">
                                        <i class="fas fa-angle-double-right"></i>  Reference
                                        </a>
                                    </h4>
                                </div>
                                <div id="collapseOne" class="panel-collapse collapse in">
                                    <div class="panel-body">
                                        <p>[20] C.-T. Liu, T.-W. Lin, Y.-H. Wu, Y.-S. Lin, H. Lee, Y. Tsao, and S.-Y. Chien, “Computation-Performance Optimization of Convolutional Neural Networks with Redundant Filter Removal,” IEEE Transactions on Circuits and Systems I 2018.</p>
                                        <p>[21] Y.-T. Hsu, Y.-C. Lin, S.-W. Fu, Y. Tsao, and T.-W. Kuo, “A Study on Speech Enhancement using Exponent-only Floating Point Quantized Neural Network (EOFP-QNN),” in Proc. SLT 2018.</p>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            <!-- End Single Item -->

            <!-- Single Item -->
                <div class="row" style="margin-bottom: 25px;" id="major-4">
                    <div class="col-lg-4 basic-info">
                        <img src="assets/img/research/S1.png" >
                    </div>
                    <div class="col-lg-8 info">
                        <h2 style="font-size: 24px; text-decoration:underline;">
                            <img src="assets/img/4.png" width="30">
                            Speech Enhancement with Direct Evaluation Metric Optimization</h2>
                            <br>
                        <p style="text-align:justify; text-indent: 2em;">
                            During the training process for an SE model, an objective function is used to optimize the model 
                            parameters. In the existing literature, there is an inconsistency between the model optimization 
                            criterion and the evaluation criterion for enhanced speech.<br>
                        </p>
                        <p style="text-align:justify; text-indent: 2em;">
                            For example, in the measurement of intelligibility, most of the evaluation metrics are based on 
                            short-time objective intelligibility (STOI) measure, while a frame based mean square error (MSE) 
                            between the enhanced speech and clean reference is widely used in the process of optimizing the model. 
                            Due to this inconsistency, there is no guarantee that the trained model will facilitate optimal 
                            performance in different applications [13]. We therefore investigated several algorithms with the 
                            aim of directly optimizing model parameters based on evaluation metrics including STOI [13], perceptual
                             evaluation of speech quality (PESQ) [14], and automatic speech recognition (ASR) [22].<br>
                        </p>
                        <p style="text-align:justify; text-indent: 2em;">
                            Reinforcement learning and GAN-based methods have also been exploited to facilitate optimization given 
                            that some evaluation metrics are complex and not differentiable. Experimental results show that by using 
                            the same specific evaluation metric as the objective function, the SE model can be trained to yield 
                            superior performance compared to the MSE to achieve a desired outcome. 
                        </p>
                        <div class="panel-group" id="accordion">
                            <div class="panel panel-default">
                                <div class="panel-heading">
                                    <h4 class="panel-title" >
                                        <a data-toggle="collapse" data-parent="#accordion" 
                                        href="#collapseOne" style="color: blue;">
                                        <i class="fas fa-angle-double-right"></i>  Reference
                                        </a>
                                    </h4>
                                </div>
                                <div id="collapseOne" class="panel-collapse collapse in">
                                    <div class="panel-body">
                                        <p>[13] S.-W. Fu, T.-W. Wang, Y. Tsao, X. Lu, and H. Kawai, “End-to-End Waveform Utterance Enhancement for Direct Evaluation Metrics Optimization by Fully Convolutional Neural Networks,” IEEE Transactions on Audio, Speech and Language Processing, vol. 26(9), pp. 1570-1584, 2018.</p>
                                        <p>[14] S.-W. Fu, Y. Tsao, H.-T. Hwang, and H.-M. Wang, “Quality-Net: An End-to-End Non-intrusive Speech Quality Assessment Model based on BLSTM,” in Proc. Interspeech 2018.</p>
                                        <p>[22] Y.-L. Shen, C.-Y. Huang, S.-S. Wang, Y. Tsao, H.-M. Wang, and T.-S. Chi, “Reinforcement Learning Based Speech Enhancement for Robust Speech Recognition,” to appear in ICASSP 2019.</p>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                 </div>
            <!-- End Single Item -->

            <!-- Single Item -->
                <div class="row" id="major-5" >
                    <div class="col-lg-4 basic-info">
                        <img src="assets/img/research/M2.png" >
                    </div>
                    <div class="col-lg-8 info">
                        <h2 style="font-size: 24px; text-decoration:underline;">
                            <img src="assets/img/5.png" width="30">
                            Multimodal Pathological Voice Classification</h2>
                            <br>
                        <p style="text-align:justify; text-indent: 2em;">
                            We have conducted research on pathological voice classification based on medical records [23] and voice 
                            signals [24]. The results showed that voice disorders can be accurately identified using voice signals 
                            and medical records when advanced signal processing and machine learning methods are utilized. Based on 
                            the voice data, we organized a pathological Voice Detection Challenge in IEEE Big Data 2018 [25], which 
                            attracted 109 participating teams from 27 different countries.<br>
                        </p>
                        <p style="text-align:justify; text-indent: 2em;">
                            More recently, we investigated the combination of acoustic signals and medical records and derived a 
                            multimodal deep learning model. The proposed model consists of two stages: the first stage processes 
                            acoustic features and medical data individually and the second stage integrates the outputs from the 
                            first stage to perform classification. The proposed multimodal deep learning frameworks were evaluated 
                            using 589 samples collected from Far Eastern Memorial Hospital, consisting of three categories of vocal 
                            disease, i.e. glottic neoplasm, phonotraumatic lesions, and vocal paralysis. We obtained promising 
                            experimental results compared to systems that use only acoustic signals or medical records.<br>
                        </p>
                        <div class="panel-group" id="accordion">
                            <div class="panel panel-default">
                                <div class="panel-heading">
                                    <h4 class="panel-title" >
                                        <a data-toggle="collapse" data-parent="#accordion" 
                                        href="#collapseOne" style="color: blue;">
                                        <i class="fas fa-angle-double-right"></i> Reference
                                        </a>
                                    </h4>
                                </div>
                                <div id="collapseOne" class="panel-collapse collapse in">
                                    <div class="panel-body">
                                    <p>[23] S.-Y. Tsui, Y. Tsao, C.-W. Lin, S.-H. Fang, and C.-T. Wang, “Demographic and Symptomatic Features of Voice Disorders and Their Potential Application in Classification using Machine Learning Algorithms,” Folia Phoniatrica et Logopaedica 2018.</p>
                                    <p>[24] C.-T. Wang, F.-C. Lin, J.-Y. Chen, M.-J. Hsiao, S.-H. Fang, Y.-H. Lai, and Y. Tsao, “Detection of Pathological Voice Using Cepstrum Vectors: A Deep Learning Approach,” Journal of Voice, 2018.</p>
                                    <p>[25] https://femh-challenge2018.weebly.com/</p>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            <!-- End Single Item -->
            </div>
        </div>
    <!-- End Advisor Details -->

    <!-- Star Advisor Area
    ============================================= -->
    <div class="advisor-area default-padding bottom-less">
        <div class="container">
            <div class="heading-left">
                <div class="row">
                    <div class="col-lg-5">
                        <h5>Team Members</h5>
                        <h2>
                            Our Expert members
                        </h2>
                    </div>
                    <div class="col-lg-6 offset-lg-1">
                        <a class="btn btn-md btn-dark border" href="members.html">View All <i class="fas fa-plus"></i></a>
                    </div>
                </div>
            </div>
        </div>
        


        <div class="container">
            <div class="advisor-items text-center">
                <div class="row">

                    <!-- Single people -->
                    <div class="single-item col-lg-3 col-md-6">
                        <div class="item">
                            <div class="thumb">
                                <img src="assets/img/people/yutsao.png">
                            </div>
                            <div class="info">
                                <h4>Dr. Yu Tsao</h4>
                                <span><i><b>Research Fellow</b></i></span>
                            </div>
                        </div>
                    </div>
                    <!-- End Item -->

                    <!-- Single people -->
                    <div class="single-item col-lg-3 col-md-6">
                        <div class="item">
                            <div class="thumb">
                                <img src="assets/img/people/syusiang.jpg">
                            </div>
                            <div class="info">
                                <h4>Syu-Siang Wang</h4>
                                <span><i><b>PostDoc</b></i></span>
                            </div>
                        </div>
                    </div>
                    <!-- End Item -->

                    <!-- Single people -->
                    <div class="single-item col-lg-3 col-md-6">
                        <div class="item">
                            <div class="thumb">
                                <img src="assets/img/people/Kai-ChunLiu.jpg">
                            </div>
                            <div class="info">
                                <h4>Kai-Chun Liu</h4>
                                <span><i><b>PostDoc</b></i></span>
                            </div>
                        </div>
                    </div>
                    <!-- End Item -->

                    <!-- Single people -->
                    <div class="single-item col-lg-3 col-md-6">
                        <div class="item">
                            <div class="thumb">
                                    <img src="assets/img/people/HuanHsinTseng.jpg">
                            </div>
                            <div class="info">
                                <h4>Huan-Hsin Tseng</h4>
                                <span><i><b>PostDoc</b></i></span>
                            </div>
                        </div>
                    </div>
                    <!-- End Item -->



                </div>
            </div>
        </div>
    </div>
    <!-- End Advisor Area -->


    <!-- Star Footer
    ============================================= -->
    <footer class="bg-dark text-light">
        <div class="container">
            <div class="f-items default-padding">
                <div class="row">

                    <div class="col-lg-4 col-md-6 item">
                        <img src="assets/img/logo3.png" alt="Logo" width="200">
                    </div>
                    
                    <div class="col-lg-4 col-md-6 item">
                        <div class="f-item link">
                            <h4 class="widget-title">Usefull Links</h4>
                            <ul>
                                <li>
                                    <a href="about-us.html">Lab</a>
                                </li>
                                <li>
                                    <a href="publication.html">Publications</a>
                                </li>
                                <li>
                                    <a href="Opensource.html">Resources</a>
                                </li>
                                <li>
                                    <a href="album.html">Activities</a>
                                </li>
                                <li>
                                    <a href="contact.html">Contact</a>
                                </li>
                            </ul>
                        </div>
                    </div>

                    <div class="col-lg-4 col-md-6 item">
                        <div class="f-item about">
                            <p>
                                Have Questions?
                            </p>
                            <p>
                                <i class="fas fa-map-marker-alt"></i>&nbsp;  3F., No.128, Sec. 2, Academia Rd., Nangang Dist., Taipei City 115, Taiwan
                            </p>
                            <p>
                                <i class="fas fa-map-marker-alt"></i>&nbsp; 115 台北市南港區研究院路二段128號<br/>中央研究院資訊科技創新研究中心三樓
                            </p>
                            <p>
                                <i class="fas fa-phone-volume"></i>&nbsp; 886-2-2787-2390
                            </p>
                            <p>
                                <i class="far fa-envelope"></i>&nbsp; yu.tsao@citi.sinica.edu.tw
                            </p>
                        </div>
                    </div>


                </div>
            </div>
        </div>
        <div>
            <p style="text-align: center;">Copyright &copy;  Bio-ASP Lab 2021</p>
        </div>
        <br>
    </footer>
    <!-- End Footer-->

    <!-- jQuery Frameworks
    ============================================= -->
    <script src="assets/js/jquery-1.12.4.min.js"></script>
    <script src="assets/js/popper.min.js"></script>
    <script src="assets/js/bootstrap.min.js"></script>
    <script src="assets/js/jquery.appear.js"></script>
    <script src="assets/js/jquery.easing.min.js"></script>
    <script src="assets/js/jquery.magnific-popup.min.js"></script>
    <script src="assets/js/modernizr.custom.13711.js"></script>
    <script src="assets/js/owl.carousel.min.js"></script>
    <script src="assets/js/wow.min.js"></script>
    <script src="assets/js/progress-bar.min.js"></script>
    <script src="assets/js/isotope.pkgd.min.js"></script>
    <script src="assets/js/imagesloaded.pkgd.min.js"></script>
    <script src="assets/js/count-to.js"></script>
    <script src="assets/js/YTPlayer.min.js"></script>
    <script src="assets/js/jquery.nice-select.min.js"></script>
    <script src="assets/js/loopcounter.js"></script>
    <script src="assets/js/bootsnav.js"></script>
    <script src="assets/js/main.js"></script>

</body>
</html>